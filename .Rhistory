mGoog <- to.monthly(GOOG)
googOpen <- Op(mGoog)
from.dat <- as.Date("01/01/08", format="%m/%d/%y")
to.dat <- as.Date("12/31/13", format="%m/%d/%y")
getSymbols("GOOG", src="google", from = from.dat, to = to.dat)
head(GOOG)
mGoog <- to.monthly(GOOG)
head(GOOG)
rm(list = ls())
library(quantmod)
from.dat <- as.Date("01/01/08", format="%m/%d/%y")
to.dat <- as.Date("12/31/13", format="%m/%d/%y")
getSymbols("GOOG", src="google", from = from.dat, to = to.dat)
head(GOOG)
library(quantmod)
from.dat <- as.Date("01/01/12", format="%m/%d/%y")
to.dat <- as.Date("12/31/15", format="%m/%d/%y")
getSymbols("GOOG", src="google", from = from.dat, to = to.dat)
head(GOOG)
?getSymbols
data(iris); library(ggplot2)
inTrain <- createDataPartition(y=iris$Species,
p=0.7, list=FALSE)
training <- iris[inTrain,]
testing <- iris[-inTrain,]
dim(training); dim(testing)
kMeans1 <- kmeans(subset(training,select=-c(Species)),centers=3)
training$clusters <- as.factor(kMeans1$cluster)
qplot(Petal.Width,Petal.Length,colour=clusters,data=training)
table(kMeans1$cluster,training$Species)
modFit <- train(clusters ~.,data=subset(training,select=-c(Species)),method="rpart")
table(predict(modFit,training),training$Species)
testClusterPred <- predict(modFit,testing)
table(testClusterPred ,testing$Species)
train <- vowel.train
head(train)
unique(train$y)
dim(train)
library(caret)
rf1 <- train(y~, method = rf, data = train)
rf1 <- train(y~., method = rf, data = train)
rf1 <- train(y~., method = "rf", data = train)
ontest <- predict(rf1, newdata = test)
train <- vowel.train
train$y <- as.factor(train$y)
test <- vowel.test
test$y <- as.factor(test$y)
set.seed(33833)
ontest <- predict(rf1, newdata = test)
ontest
ontest <- predict(rf1, newdata = test)
test$predGood <- ontest == test$y
table(pred,test$y)
ontest <- predict(rf1, newdata = test)
test$predGood <- ontest == test$y
table(ontest,test$y)
test$predGood
rf1
varImp(rf1)
rf1 <- train(y~., method = "rf", data = train, prox = TRUE)
ontest <- predict(rf1, newdata = test)
test$predGood <- ontest == test$y
table(ontest,test$y)
confusionMatrix(test$y, ontest)
ontest == test$y
table(ontest,test$y)
plot(ontest,test$y)
library(ElemStatLearn)
data(vowel.train)
data(vowel.test)
train <- vowel.train
train$y <- as.factor(train$y)
test <- vowel.test
test$y <- as.factor(test$y)
set.seed(33833)
library(caret)
rf1 <- train(y~., method = "rf", data = train, prox = TRUE)
ontest <- predict(rf1, newdata = test)
#test$predGood <- ontest == test$y
#table(ontest,test$y)
confusionMatrix(test$y, ontest)
rf2 <- train(y~., method = "gbm", data = train, prox = TRUE)
ontest2 <- predict(rf2, newdata = test)
#test$predGood2 <- ontest2 == test$y
#table(ontest2,test$y)
confusionMatrix(test$y, ontest2)
rf2 <- train(y~., method = "gbm", data = train, prox = TRUE)
library(ElemStatLearn)
data(vowel.train)
data(vowel.test)
train <- vowel.train
train$y <- as.factor(train$y)
test <- vowel.test
test$y <- as.factor(test$y)
set.seed(33833)
rf2 <- train(y~., method = "gbm", data = train, prox = TRUE)
rf2 <- train(y~., method = "gbm", data = train)
rf2 <- train(y~., method = "gbm", data = train)
rf2 <- train(y~., method = "gbm", data = train, prox = TRUE)
rf2 <- train(y~., method = "gbm", data = train, verbose=FALSE)
ontest2 <- predict(rf2, newdata = test)
#test$predGood2 <- ontest2 == test$y
#table(ontest2,test$y)
confusionMatrix(test$y, ontest2)
confusionMatrix(test$y, ontest)
equalp = ontest == ontest2
equalp
mean(equalp)
predDF <- data.frame(ontest,ontest2,y=test$y)
combModFit <- train(y ~.,method="gam",data=predDF)
combPred <- predict(combModFit,predDF)
confusionMatrix(test$y, combPred)
head(predDF)
str(predDF)
confusionMatrix(predDF$y, combPred)
confusionMatrix(test$y, ontest)$overall[1]
mean(equalpredictions)
equalpredictions = ontest == ontest2
mean(equalpredictions)
equalpredictions <- ontest == ontest2
mean(equalpredictions)
pred_rf <- ontest
pred_gbm <- ontest2
sum(pred_rf[predDF$pred_rf == predDF$pred_gbm] ==
predDF$y[predDF$pred_rf == predDF$pred_gbm]) /
sum(predDF$pred_rf == predDF$pred_gbm)
predDF <- data.frame(pred_rf, pred_gbm, y=test$y)
sum(pred_rf[predDF$pred_rf == predDF$pred_gbm] ==
predDF$y[predDF$pred_rf == predDF$pred_gbm]) /
sum(predDF$pred_rf == predDF$pred_gbm)
head(combPred)
combModFit <- train(y ~.,method="glm",data=predDF)
combPred <- predict(combModFit,predDF)
confusionMatrix(predDF$y, combPred)
confusionMatrix(test$y[equalsIndex], ontest[equalsIndex])
equalsIndex <- ontest == ontest2
mean(equalsIndex)
confusionMatrix(test$y[equalsIndex], ontest[equalsIndex])
pred_rf <- ontest
pred_gbm <- ontest2
predDF <- data.frame(pred_rf, pred_gbm, y=test$y)
sum(pred_rf[predDF$pred_rf == predDF$pred_gbm] ==
predDF$y[predDF$pred_rf == predDF$pred_gbm]) /
sum(predDF$pred_rf == predDF$pred_gbm)
confusionMatrix(test$y[equalsIndex], ontest2[equalsIndex])
confusionMatrix(test$y[equalsIndex], ontest[equalsIndex])
confusionMatrix(ontest, ontest2)
predDF <- data.frame(ontest,ontest2,y=test$y)
combModFit <- train(y ~.,method="rf",data=predDF)
combPred <- predict(combModFit,predDF)
confusionMatrix(predDF$y, combPred)
predDF <- data.frame(ontest,ontest2,y=test$y)
combModFit2 <- train(y ~.,method="gbm",data=predDF, verbose=FALSE)
combPred2 <- predict(combModFit2,predDF)
confusionMatrix(predDF$y, combPred2)
confusionMatrix(test$y, combPred2)  ## Accuracy : 0.6775
rm(list = ls())
library(caret)
library(gbm)
set.seed(3433)
library(AppliedPredictiveModeling)
data(AlzheimerDisease)
adData = data.frame(diagnosis,predictors)
inTrain = createDataPartition(adData$diagnosis, p = 3/4)[[1]]
training = adData[ inTrain,]
testing = adData[-inTrain,]
names(training)
rf1 <- train(diagnosis~., method = "rf", data = training, prox = TRUE)
gbm1 <- train(diagnosis~., method = "gbm", data = training, verbose=FALSE)
lda1 <- train(diagnosis ~ ., data=training, method="lda")
lda1
gbm1
rfhat <- predict(rf1, testing)
gbmhat <- predict(gbm1, testing)
ldahat <- predict(lda1, testing)
confusionMatrix(rfhat, testing$diagnosis)
confusionMatrix(gbmhat, testing$diagnosis)
confusionMatrix(ldahat, testing$diagnosis)
cMrf  <- confusionMatrix(rfhat, testing$diagnosis)
cMgbm <- confusionMatrix(gbmhat, testing$diagnosis)
cMlda <- confusionMatrix(ldahat, testing$diagnosis)
cMrf$overall[1]
cbind(cMrf$overall[1], cMgbm$overall[1], cMlda$overall[1])
cbind("RF" = cMrf$overall[1], "GBM" = cMgbm$overall[1], "LDA" cMlda$overall[1])
cbind(cMrf$overall[1], cMgbm$overall[1], cMlda$overall[1])
predDF <- data.frame(rfhat, gbmhat, ldahat, testing$diagnosis)
head(predDF)
stack1  <- train(diagnosis~., method = "rf", data = predDF, prox = TRUE)
dim(predDF)
dim(testing)
stack1  <- train(testing.diagnosis~., method = "rf", data = predDF, prox = TRUE)
stackhat <- predict(stack1, predDF)
confusionMatrix(stackhat, predDF$testing.diagnosis)
rfhat2  <- predict(rf1, training)
gbmhat2 <- predict(gbm1, training)
ldahat2 <- predict(lda1, training)
stack2  <- train(training.diagnosis~., method = "rf", data = predDF2, prox = TRUE)
predDF2 <- data.frame(rfhat2, gbmhat2, ldahat2, training$diagnosis)
stack2  <- train(training.diagnosis~., method = "rf", data = predDF2, prox = TRUE)
stack2hat <- predict(stack2, testing)
dim(testing)
dim(predDF2)
dim(training)
confusionMatrix(stack2hat, predDF$training.diagnosis)
confusionMatrix(stack2hat, testing$diagnosis)
length(stack2hat)
predDF2 <- data.frame(rfhat2, gbmhat2, ldahat2, training$diagnosis)
stack2  <- train(training.diagnosis~., method = "rf", data = predDF2, prox = TRUE)
stack2hat <- predict(stack2, testing)
stack2
rm(list = ls())
library(caret)
library(gbm)
set.seed(3433)
library(AppliedPredictiveModeling)
data(AlzheimerDisease)
adData = data.frame(diagnosis,predictors)
inTrain = createDataPartition(adData$diagnosis, p = 3/4)[[1]]
training = adData[ inTrain,]
testing = adData[-inTrain,]
set.seed(62433)
## run the 3 regressions
rf1  <- train(diagnosis~., method = "rf", data = training, prox = TRUE)
gbm1 <- train(diagnosis~., method = "gbm", data = training, verbose=FALSE)
lda1 <- train(diagnosis ~ ., data=training, method="lda")
rfhat  <- predict(rf1, testing)
gbmhat <- predict(gbm1, testing)
ldahat <- predict(lda1, testing)
## Get confussion matrices and find accuracies
cMrf  <- confusionMatrix(rfhat, testing$diagnosis)
cMgbm <- confusionMatrix(gbmhat, testing$diagnosis)
cMlda <- confusionMatrix(ldahat, testing$diagnosis)
cbind(cMrf$overall[1], cMgbm$overall[1], cMlda$overall[1])
rfhat2  <- predict(rf1, training)
gbmhat2 <- predict(gbm1, training)
ldahat2 <- predict(lda1, training)
predDF2 <- data.frame(rfhat2, gbmhat2, ldahat2, training$diagnosis)
dim(predDF2)
head(predDF2)
tail(predDF2)
stack2  <- train(training.diagnosis~., method = "rf", data = predDF2, prox = TRUE)
stack2hat <- predict(stack2, testing)
predDF2 <- data.frame(rfhat2, gbmhat2, ldahat2, diagnosis = training$diagnosis)
stack2  <- train(diagnosis~., method = "rf", data = predDF2, prox = TRUE)
stack2hat <- predict(stack2, testing)
predTDF <- data.frame(rfhat2 = rfhat, gbmhat2 = gbmhat, ldaha2 = ldahat)
stack2hat <- predict(stack2, predTDF)
predTDF <- data.frame(rfhat2 = rfhat, gbmhat2 = gbmhat, ldahat2 = ldahat)
stack2hat <- predict(stack2, predTDF)
confusionMatrix(stack2hat, testing$diagnosis)
cMstack   <- confusionMatrix(stack2hat, testing$diagnosis)
cbind(cMrf$overall[1], cMgbm$overall[1], cMlda$overall[1], cMstack$overall[1])
rm(list = ls())
set.seed(3523)
library(AppliedPredictiveModeling)
data(concrete)
inTrain = createDataPartition(concrete$CompressiveStrength, p = 3/4)[[1]]
training = concrete[ inTrain,]
testing = concrete[-inTrain,]
set.seed(233)
library(lars)
install.packages("lars")
library(lars)
?plot.enet
library(carat)
library(caret)
?plot.enet
names(training)
covnames <- names(training[-9])
covnames
covnames <- names(training[-9])
y <- training$CompressiveStrength
x <- training[,covnames]
lasso.fit <- lars(as.matrix(x), y, type="lasso", trace=TRUE)
covnames[6]
yhat <- predict(lasso.fit, training)
yhat <- predict(lasso.fit, x)
confusionMatrix(yhat, y)
yhat <- predict(lasso.fit, x)
dim(yhat)
dim(x)
yhat <- predict(lasso.fit)
yhat
plot(lasso.fit, breaks=FALSE)
legend("topleft", covnames, pch=8, lty=1:length(covnames), col=1:length(covnames))
plot(lasso.fit, breaks=FALSE)
mod_lasso <- train(CompressiveStrength ~ ., data = training, method = "lasso")
library(elasticnet)
plot.enet(mod_lasso$finalModel, xvar = "penalty", use.color = TRUE)
lasso.fit <- lars(as.matrix(x), y, type="lasso", trace=TRUE)
lassoP <- predict(mod_lasso, training)
confusionMatrix(lassoP, training$CompressiveStrength)
head(lassoP)
dim(training)
length(lassoP)
confusionMatrix(lassoP, y)
head(training$CompressiveStrength)
plot(lassoP, y)
class(lassoP)
class(training$CompressiveStrength)
plot(y, lassoP)
plot(y)
plot(y, lassoP)
mod_lasso <- train(CompressiveStrength ~ ., data = training, method = "lm")
lassoP <- predict(mod_lasso, training)
plot(y, lassoP)
lassoP <- predict(mod_lasso, training)
plot(y, lassoP)
mod_lasso <- train(CompressiveStrength ~ ., data = training, method = "lasso")
lassoP <- predict(mod_lasso, training)
plot(y, lassoP)
plot(y)
plot(y, lassoP)
mod_lasso
mod_lasso <- train(CompressiveStrength ~ ., data = training, method = "lasso")
mod_lasso
getwd
getwd()
dat = read.csv("gaData.csv")
training = dat[year(dat$date) < 2012,]
testing = dat[(year(dat$date)) > 2011,]
tstrain = ts(training$visitsTumblr)
library(lubridate) # For year() function below
install.packages("lubridate")
library(lubridate) # For year() function below
training = dat[year(dat$date) < 2012,]
testing = dat[(year(dat$date)) > 2011,]
tstrain = ts(training$visitsTumblr)
library(forecast)
install.packages("forecast")
?forecast
library(forecast)
library(forecast)
?forecast
?bats()
head(training)
head(tstrain)
dim(training)
dim(testing)
dim(tstrain)
length(tstrain)
?ts
for1 <- bats(tstrain)
for1
plot(tstrain)
plot(training)
plot(training$visitsTumblr)
plot(tstrain)
class(tstrain)
?nats
?bats
testhat <- predict(for1, testing)
tstest(testing$visitsTumblr)
tstest  <- ts(testing$visitsTumblr)
testhat <- predict(for1, tstest)
testhat <- forecast(for1, tstest)
?forecast
head(tstest)
tstest
testhat <- forecast(for1, 235)
testhat
tstrain
tstest
dim(testhat)
class(testhat)
names(testhat)
testhat$lower
testhat$lower[2]
testhat$lower[,2]
index <- tstrain >= testhat$lower[,2] & tstrain <= testhat$upper[,2]
index
testhat$upper[,2]
upper <- as.numeric(testhat$upper[,2])
upper
upper <- as.numeric(testhat$upper[,2])
lower <- as.numeric(testhat$lower[,2])
index <- tstrain >= lower & tstrain <= upper
testN <-testing$visitsTumblr
index <- testN >= lower & testN <= upper
sum(index)
mean(index)
testhat <- forecast(for1, level =95, h = length(tstest))
testhat
names(testhat)
testhat$upper[,2]
testhat$upper
for1    <- bats(tstrain)
tstest  <- ts(testing$visitsTumblr)
testhat <- forecast(for1, 235)
upper <- as.numeric(testhat$upper[,2])
lower <- as.numeric(testhat$lower[,2])
testN <-testing$visitsTumblr
index <- testN >= lower & testN <= upper
mean(index)
testhat <- forecast(for1, level = 95, h = dim(testing)[1])
for1    <- bats(tstrain)
testhat <- forecast(for1, level = 95, h = dim(testing)[1])
upper   <- as.numeric(testhat$upper)
lower   <- as.numeric(testhat$lower)
testN   <-testing$visitsTumblr
index   <- testN >= lower & testN <= upper
mean(index)
library(e1071)
?vvm
?svm
svm1 <- svm(CompressiveStrength ~ ., data = training)
head(training)
set.seed(3523)
library(AppliedPredictiveModeling)
data(concrete)
inTrain = createDataPartition(concrete$CompressiveStrength, p = 3/4)[[1]]
training = concrete[ inTrain,]
testing = concrete[-inTrain,]
## Set the seed to 325 and fit a support vector machine using the e1071 package
## to predict Compressive Strength using the default settings. Predict on the
## testing set. Calculate RMSE
library(e1071)
set.seed(325)
svm1 <- svm(CompressiveStrength ~ ., data = training)
summary(svm1)
yhat <- predict(svm1, testing)
head(yhat)
head(testing$CompressiveStrength)
mean((yhat - testing$CompressiveStrength)^2)
head(training)
head(testing)
head(yhat)
svm1
summary(svm1)
sqrt(mean((yhat - testing$CompressiveStrength)^2))
rmse1 <- sqrt(mean((yhat - testing$CompressiveStrength)^2))
rmse1
radiusExample <- c(3.5, 10^7, 10^(-4), "a", (-6))
radius <- radiusExample
if (radius >= 0& is.numeric(radius) ) {
circ <- paste(format(signif(circ   <- 2*pi*radius, 4),
big.mark=","), "units")
}else {circ <- "NA"}
radius
radiusExample <- c(3.5, 10^7, 10^(-4), "a", (-6))
radius <- data.frame(radiusExample)
if (radius[1] >= 0& is.numeric(radius) ) {
circ <- paste(format(signif(circ   <- 2*pi*radius, 4),
big.mark=","), "units")
}else {circ <- "NA"}
knitr::kable(circ)
radiusExample <- c(1,2,3,4,5); for (i = 1:2){
radius <- data.frame(radiusExample)
if (radius[i] >= 0& is.numeric(radius) ) {
circ[i] <- paste(format(signif(circ   <- 2*pi*radius, 4),
big.mark=","), "units")
}else {circ <- "NA"}}
circ
radiusExample <- c(1,2,3,4,5); for (i = 1:2){
radius <- radiusExample[i]
if (radius >= 0& is.numeric(radius) ) {
circ[i] <- paste(format(signif(circ   <- 2*pi*radius, 4),
big.mark=","), "units")
}else {circ <- "NA"}}
circ
radiusExample <- c(1,2,3,4,5); for (i in 1:2){
radius <- radiusExample[i]
if (radius >= 0& is.numeric(radius) ) {
circ[i] <- paste(format(signif(circ   <- 2*pi*radius, 4),
big.mark=","), "units")
}else {circ <- "NA"}}
circ
radiusExample <- c(1,2,3,4,5); for (i in 1:5){
radius <- radiusExample[i]
if (radius >= 0& is.numeric(radius) ) {
circ[i] <- paste(format(signif(circ   <- 2*pi*radius, 4),
big.mark=","), "units")
}else {circ <- "NA"}}
circ
install.packages(c("assertthat", "backports", "boot", "brglm", "car", "checkmate", "coin", "curl", "DBI", "dplyr", "dtplyr", "earth", "evaluate", "fastICA", "fields", "forecast", "foreign", "formatR", "Formula", "gdata", "GGally", "Hmisc", "htmltools", "htmlwidgets", "httpuv", "jsonlite", "knitr", "maps", "markdown", "MASS", "Matrix", "memoise", "mgcv", "plotly", "plotmo", "pracma", "pROC", "psych", "purrr", "quantmod", "R6", "RANN", "Rcpp", "RcppArmadillo", "RcppEigen", "readr", "RMySQL", "rpart", "rsconnect", "RSQLite", "sandwich", "sp", "spam", "sqldf", "stringdist", "stringi", "subselect", "tibble", "tidyr", "tseries", "TTR", "units", "XLConnect", "XLConnectJars", "XML", "xts"))
install.packages(c("boot", "mgcv"))
install.packages("ggplot2")
install.packages("dplyr")
install.packages("gridExtra")
install.packages("memisc")
install.packages("data.table")
install.packages("pander")
install.packages("kableExtra")
??kableExtra
7000000/15
7000000/23
source('~/MEGA/JHCapstone/report_dataGenerator.R')
n4grams
n4gram
pred
cleancorpus1gram
con<-file("clean_corpus.txt")
open(con)
corpus_sample <- readLines(con, n = 10, skipNul = TRUE)
close(con)
write(corpus_sample, "data/corp_sample2.txt")
con<-file("data/clean_corpus.txt")
open(con)
corpus_sample <- readLines(con, n = 10, skipNul = TRUE)
close(con)
write(corpus_sample, "data/corp_sample2.txt")
source('~/MEGA/corpus_analysis/report_dataGenerator.R')
source('~/MEGA/corpus_analysis/report_dataGenerator.R')
source('~/MEGA/corpus_analysis/report_dataGenerator.R')
pred
wcode
pcode
n4gram
pred
cleancorpus1gram
source('~/MEGA/corpus_analysis/report_dataGenerator.R')
pred
